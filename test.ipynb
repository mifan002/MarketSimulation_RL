{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-06-09T15:30:01.317120537Z",
     "start_time": "2023-06-09T15:29:05.338171986Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Using cuda device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 10.3     |\n",
      "|    ep_rew_mean     | 1.23e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 918      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 9.52         |\n",
      "|    ep_rew_mean          | 1.15e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 761          |\n",
      "|    iterations           | 2            |\n",
      "|    time_elapsed         | 5            |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0024758424 |\n",
      "|    clip_fraction        | 0.0042       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.23        |\n",
      "|    explained_variance   | -6.53e-05    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 5.2e+05      |\n",
      "|    n_updates            | 10           |\n",
      "|    policy_gradient_loss | -0.0167      |\n",
      "|    value_loss           | 9.13e+05     |\n",
      "------------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                |            |\n",
      "|    ep_len_mean          | 9.47       |\n",
      "|    ep_rew_mean          | 1.18e+03   |\n",
      "| time/                   |            |\n",
      "|    fps                  | 722        |\n",
      "|    iterations           | 3          |\n",
      "|    time_elapsed         | 8          |\n",
      "|    total_timesteps      | 6144       |\n",
      "| train/                  |            |\n",
      "|    approx_kl            | 0.00168517 |\n",
      "|    clip_fraction        | 0.000293   |\n",
      "|    clip_range           | 0.2        |\n",
      "|    entropy_loss         | -9.23      |\n",
      "|    explained_variance   | 4.92e-05   |\n",
      "|    learning_rate        | 0.0003     |\n",
      "|    loss                 | 5.62e+05   |\n",
      "|    n_updates            | 20         |\n",
      "|    policy_gradient_loss | -0.0125    |\n",
      "|    value_loss           | 1.13e+06   |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 19.3        |\n",
      "|    ep_rew_mean          | 2.2e+03     |\n",
      "| time/                   |             |\n",
      "|    fps                  | 704         |\n",
      "|    iterations           | 4           |\n",
      "|    time_elapsed         | 11          |\n",
      "|    total_timesteps      | 8192        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.002218791 |\n",
      "|    clip_fraction        | 0.00117     |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -9.22       |\n",
      "|    explained_variance   | -3.3e-05    |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 3.66e+05    |\n",
      "|    n_updates            | 30          |\n",
      "|    policy_gradient_loss | -0.0148     |\n",
      "|    value_loss           | 9.19e+05    |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 9.88         |\n",
      "|    ep_rew_mean          | 1.2e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 691          |\n",
      "|    iterations           | 5            |\n",
      "|    time_elapsed         | 14           |\n",
      "|    total_timesteps      | 10240        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009060679 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.22        |\n",
      "|    explained_variance   | 2.21e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.27e+05     |\n",
      "|    n_updates            | 40           |\n",
      "|    policy_gradient_loss | -0.00835     |\n",
      "|    value_loss           | 1.75e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 16.9         |\n",
      "|    ep_rew_mean          | 1.97e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 684          |\n",
      "|    iterations           | 6            |\n",
      "|    time_elapsed         | 17           |\n",
      "|    total_timesteps      | 12288        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0018382544 |\n",
      "|    clip_fraction        | 0.000586     |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.22        |\n",
      "|    explained_variance   | -5.96e-06    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 3.81e+05     |\n",
      "|    n_updates            | 50           |\n",
      "|    policy_gradient_loss | -0.0132      |\n",
      "|    value_loss           | 9.18e+05     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 18           |\n",
      "|    ep_rew_mean          | 2.1e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 675          |\n",
      "|    iterations           | 7            |\n",
      "|    time_elapsed         | 21           |\n",
      "|    total_timesteps      | 14336        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0011105307 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.21        |\n",
      "|    explained_variance   | -1.19e-06    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 6.17e+05     |\n",
      "|    n_updates            | 60           |\n",
      "|    policy_gradient_loss | -0.00888     |\n",
      "|    value_loss           | 1.39e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 17.4         |\n",
      "|    ep_rew_mean          | 2.04e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 669          |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 24           |\n",
      "|    total_timesteps      | 16384        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0009988985 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.21        |\n",
      "|    explained_variance   | 1.25e-06     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 8.64e+05     |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -0.0087      |\n",
      "|    value_loss           | 1.64e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 18.9         |\n",
      "|    ep_rew_mean          | 2.2e+03      |\n",
      "| time/                   |              |\n",
      "|    fps                  | 666          |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 27           |\n",
      "|    total_timesteps      | 18432        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0010532753 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.2         |\n",
      "|    explained_variance   | 1.79e-07     |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 7.15e+05     |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -0.00903     |\n",
      "|    value_loss           | 1.63e+06     |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 24.1         |\n",
      "|    ep_rew_mean          | 2.77e+03     |\n",
      "| time/                   |              |\n",
      "|    fps                  | 663          |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 30           |\n",
      "|    total_timesteps      | 20480        |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0012007805 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -9.2         |\n",
      "|    explained_variance   | -8.34e-07    |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 9.64e+05     |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -0.00964     |\n",
      "|    value_loss           | 1.82e+06     |\n",
      "------------------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 9.3      |\n",
      "|    ep_rew_mean     | 1.14e+03 |\n",
      "| time/              |          |\n",
      "|    fps             | 906      |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 2        |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 9.51     |\n",
      "|    ep_rew_mean            | 1.15e+03 |\n",
      "| time/                     |          |\n",
      "|    fps                    | 857      |\n",
      "|    iterations             | 2        |\n",
      "|    time_elapsed           | 4        |\n",
      "|    total_timesteps        | 4096     |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 7.45e-05 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00428  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 1        |\n",
      "|    policy_objective       | 0.0603   |\n",
      "|    value_loss             | 9.01e+05 |\n",
      "----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 8.04      |\n",
      "|    ep_rew_mean            | 1.03e+03  |\n",
      "| time/                     |           |\n",
      "|    fps                    | 857       |\n",
      "|    iterations             | 3         |\n",
      "|    time_elapsed           | 7         |\n",
      "|    total_timesteps        | 6144      |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | -3.08e-05 |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00413   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 2         |\n",
      "|    policy_objective       | 0.0618    |\n",
      "|    value_loss             | 8.47e+05  |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                  |           |\n",
      "|    ep_len_mean            | 14.1      |\n",
      "|    ep_rew_mean            | 1.66e+03  |\n",
      "| time/                     |           |\n",
      "|    fps                    | 847       |\n",
      "|    iterations             | 4         |\n",
      "|    time_elapsed           | 9         |\n",
      "|    total_timesteps        | 8192      |\n",
      "| train/                    |           |\n",
      "|    explained_variance     | -2.98e-06 |\n",
      "|    is_line_search_success | 1         |\n",
      "|    kl_divergence_loss     | 0.00393   |\n",
      "|    learning_rate          | 0.001     |\n",
      "|    n_updates              | 3         |\n",
      "|    policy_objective       | 0.0563    |\n",
      "|    value_loss             | 1.19e+06  |\n",
      "-----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 16.2     |\n",
      "|    ep_rew_mean            | 1.9e+03  |\n",
      "| time/                     |          |\n",
      "|    fps                    | 847      |\n",
      "|    iterations             | 5        |\n",
      "|    time_elapsed           | 12       |\n",
      "|    total_timesteps        | 10240    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 1.85e-06 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00403  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 4        |\n",
      "|    policy_objective       | 0.0544   |\n",
      "|    value_loss             | 1.56e+06 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 15.9     |\n",
      "|    ep_rew_mean            | 1.93e+03 |\n",
      "| time/                     |          |\n",
      "|    fps                    | 849      |\n",
      "|    iterations             | 6        |\n",
      "|    time_elapsed           | 14       |\n",
      "|    total_timesteps        | 12288    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 1.07e-06 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00424  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 5        |\n",
      "|    policy_objective       | 0.0542   |\n",
      "|    value_loss             | 1.91e+06 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 14.8     |\n",
      "|    ep_rew_mean            | 1.79e+03 |\n",
      "| time/                     |          |\n",
      "|    fps                    | 850      |\n",
      "|    iterations             | 7        |\n",
      "|    time_elapsed           | 16       |\n",
      "|    total_timesteps        | 14336    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 5.96e-07 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00437  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 6        |\n",
      "|    policy_objective       | 0.0522   |\n",
      "|    value_loss             | 1.69e+06 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 27       |\n",
      "|    ep_rew_mean            | 3.13e+03 |\n",
      "| time/                     |          |\n",
      "|    fps                    | 852      |\n",
      "|    iterations             | 8        |\n",
      "|    time_elapsed           | 19       |\n",
      "|    total_timesteps        | 16384    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 4.77e-07 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00413  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 7        |\n",
      "|    policy_objective       | 0.052    |\n",
      "|    value_loss             | 1.46e+06 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 41.2     |\n",
      "|    ep_rew_mean            | 4.69e+03 |\n",
      "| time/                     |          |\n",
      "|    fps                    | 853      |\n",
      "|    iterations             | 9        |\n",
      "|    time_elapsed           | 21       |\n",
      "|    total_timesteps        | 18432    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 2.38e-07 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00378  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 8        |\n",
      "|    policy_objective       | 0.0505   |\n",
      "|    value_loss             | 2.65e+06 |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| rollout/                  |          |\n",
      "|    ep_len_mean            | 25.4     |\n",
      "|    ep_rew_mean            | 3.01e+03 |\n",
      "| time/                     |          |\n",
      "|    fps                    | 854      |\n",
      "|    iterations             | 10       |\n",
      "|    time_elapsed           | 23       |\n",
      "|    total_timesteps        | 20480    |\n",
      "| train/                    |          |\n",
      "|    explained_variance     | 6.56e-07 |\n",
      "|    is_line_search_success | 1        |\n",
      "|    kl_divergence_loss     | 0.00406  |\n",
      "|    learning_rate          | 0.001    |\n",
      "|    n_updates              | 9        |\n",
      "|    policy_objective       | 0.0465   |\n",
      "|    value_loss             | 2.56e+06 |\n",
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": "<sb3_contrib.trpo.trpo.TRPO at 0x7f0f5571d340>"
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the environment\n",
    "import gym\n",
    "from gym import spaces\n",
    "import numpy as np\n",
    "from stable_baselines3 import PPO, A2C, DQN\n",
    "from sb3_contrib import TRPO\n",
    "\n",
    "# Define the market environment\n",
    "class MarketEnvironment(gym.Env):\n",
    "    def __init__(self):\n",
    "        super(MarketEnvironment, self).__init__()\n",
    "\n",
    "        # Define action and observation space\n",
    "        # They must be gym.spaces objects\n",
    "        # Example when using discrete actions, Box(2,) for two sellers\n",
    "        self.action_space = spaces.MultiDiscrete([101, 101])\n",
    "\n",
    "        # Prices could range from 0 to 100, there are four buyers\n",
    "        self.observation_space = spaces.Box(low=0, high=100, shape=(6,))\n",
    "        self.prices_history = []\n",
    "\n",
    "\n",
    "        # Initialize state\n",
    "        self.reset()\n",
    "\n",
    "    def step(self, action):\n",
    "        # Execute one time step within the environment\n",
    "        assert self.action_space.contains(action)\n",
    "\n",
    "        # Simple model: buyers buy from the cheapest seller\n",
    "        sorted_sellers = np.argsort(action)\n",
    "        self.state[0] = action[sorted_sellers[0]]\n",
    "        self.state[1] = action[sorted_sellers[1]]\n",
    "\n",
    "        # Distribute the buyers\n",
    "        for i in range(2, 6):\n",
    "            if self.state[i] >= self.state[0]:\n",
    "                self.state[0] += self.state[i]\n",
    "                self.state[i] = 0\n",
    "            elif self.state[i] >= self.state[1]:\n",
    "                self.state[1] += self.state[i]\n",
    "                self.state[i] = 0\n",
    "\n",
    "        # Set reward as the profit of the sellers\n",
    "        reward = self.state[0] + self.state[1]\n",
    "\n",
    "        # Set done flag if all buyers have bought the products\n",
    "        done = np.sum(self.state[2:]) == 0\n",
    "\n",
    "        # Save the prices to history\n",
    "        self.prices_history.append(action)\n",
    "\n",
    "        return self.state, reward, done, {}\n",
    "\n",
    "\n",
    "    def reset(self):\n",
    "        # Reset the state of the environment to an initial state\n",
    "        self.state = np.zeros(6)\n",
    "        # Initialize buyers' willingness to pay\n",
    "        self.state[2:6] = np.random.uniform(low=0, high=100, size=4)\n",
    "        return self.state\n",
    "\n",
    "# Initialize environment\n",
    "env = MarketEnvironment()\n",
    "\n",
    "# Initialize reinforcement learning agents\n",
    "model1 = PPO(\"MlpPolicy\", env, verbose=1)\n",
    "model2 = TRPO(\"MlpPolicy\", env, verbose=1)\n",
    "# Train agents\n",
    "model1.learn(total_timesteps=20000)\n",
    "model2.learn(total_timesteps=20000)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean reward for the first agent: 2160.6553933399573\n",
      "Mean reward for the second agent: 12321.024391415709\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, env, num_episodes=100):\n",
    "    episode_rewards = []\n",
    "    episode_actions = []\n",
    "    for i in range(num_episodes):\n",
    "        obs = env.reset()\n",
    "        done = False\n",
    "        episode_reward = 0\n",
    "        actions = []\n",
    "        while not done:\n",
    "            action, _ = model.predict(obs)\n",
    "            obs, reward, done, info = env.step(action)\n",
    "            episode_reward += reward\n",
    "            actions.append(action)\n",
    "        episode_rewards.append(episode_reward)\n",
    "        episode_actions.append(actions)\n",
    "    return np.mean(episode_rewards), episode_actions\n",
    "\n",
    "# Evaluate the first agent\n",
    "mean_reward1, actions1 = evaluate_model(model1, env)\n",
    "print(f\"Mean reward for the first agent: {mean_reward1}\")\n",
    "\n",
    "# Evaluate the second agent\n",
    "mean_reward2, actions2 = evaluate_model(model2, env)\n",
    "print(f\"Mean reward for the second agent: {mean_reward2}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-06-09T15:31:08.167854587Z",
     "start_time": "2023-06-09T15:30:58.653149106Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
